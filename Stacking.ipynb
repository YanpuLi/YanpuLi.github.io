{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score , StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "logreg_tuned_parameters = [{'C': np.logspace(-1, 2, 4),'penalty':['l1','l2']}]\n",
    "classifiers.append([\"Logistic Regression\", LogisticRegression(), logreg_tuned_parameters])\n",
    "\n",
    "svm_tuned_parameters = [{'kernel': ['linear','rbf'],\n",
    "                             'C': np.logspace(-1, 2, 4),\n",
    "                             'gamma': np.logspace(-4, 0, 5)}]\n",
    "classifiers.append([\"SVM\", SVC(), svm_tuned_parameters])\n",
    " \n",
    "rf_tuned_parameters = [{\"criterion\": [\"gini\"],}]                \n",
    "classifiers.append([\"RandomForest\", RandomForestClassifier(n_jobs=-1), rf_tuned_parameters])\n",
    "\n",
    "knn_tuned_parameters = [{\"n_neighbors\": [1, 3, 5, 10, 20]}]\n",
    "classifiers.append([\"kNN\", KNeighborsClassifier(),knn_tuned_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gsCV_accuracy(name,classifier, params, train, target):\n",
    " \n",
    "    print (name+\":\")\n",
    "    gs= GridSearchCV(classifier, params, n_jobs=-1, cv=5,scoring=\"accuracy\")\n",
    "    gs.fit(train, target)\n",
    "    #print (gs.best_params_, gs.best_score_)\n",
    "    \n",
    "    predict = gs.best_estimator_.predict(train)\n",
    "    print(metrics.classification_report(target,predict))\n",
    "    print(metrics.confusion_matrix(target, predict))\n",
    "    print(cross_val_score(gs.best_estimator_, train,target,cv= 5).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       0.97      0.95      0.96        37\n",
      "          2       0.95      0.97      0.96        37\n",
      "\n",
      "avg / total       0.97      0.97      0.97       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 35  2]\n",
      " [ 0  1 36]]\n",
      "0.953122529644\n",
      "SVM:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      0.95      0.97        37\n",
      "          2       0.95      1.00      0.97        37\n",
      "\n",
      "avg / total       0.98      0.98      0.98       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 35  2]\n",
      " [ 0  0 37]]\n",
      "0.970909090909\n",
      "RandomForest:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       0.95      1.00      0.97        37\n",
      "          2       1.00      0.95      0.97        37\n",
      "\n",
      "avg / total       0.98      0.98      0.98       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  2 35]]\n",
      "0.934031620553\n",
      "kNN:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      1.00      1.00        37\n",
      "          2       1.00      1.00      1.00        37\n",
      "\n",
      "avg / total       1.00      1.00      1.00       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  0 37]]\n",
      "0.952213438735\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classifiers)):\n",
    "    gsCV_accuracy(classifiers[i][0],classifiers[i][1], classifiers[i][2], X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stacking(object):\n",
    "\n",
    "    def __init__(self, seed, n_fold, base_learners, meta_learner):\n",
    "        self.seed = seed\n",
    "        self.n_fold = n_fold\n",
    "        self.base_learners = base_learners\n",
    "        self.meta_learner = meta_learner\n",
    "        self.T = len(base_learners) # num of base learners\n",
    "\n",
    "    def generateBaseLearner(self, X_tr, y_tr, X_te, y_te):\n",
    "    \n",
    "        n1 = X_tr.shape[0]\n",
    "        n2 = X_te.shape[0]\n",
    "\n",
    "        kf = KFold(n1, n_folds= self.n_fold, random_state= self.seed)\n",
    "\n",
    "        #constructing data for meta learner\n",
    "        meta_train = np.zeros((n1, self.T))\n",
    "        meta_test = np.zeros((n2, self.T))\n",
    "\n",
    "        for i, clf in enumerate(self.base_learners):\n",
    "            meta_test_i = np.zeros((n2, self.n_fold))\n",
    "            for j, (train_index, test_index) in enumerate(kf):\n",
    "                X_train = X_tr[train_index]\n",
    "                y_train = y_tr[train_index]\n",
    "                X_holdout = X_tr[test_index]\n",
    "                y_holdout = y_tr[test_index]\n",
    "           \n",
    "                clf[1].fit(X_train, y_train)\n",
    "                y_pred = clf[1].predict(X_holdout)[:]\n",
    "                \n",
    "                print 'Base Learner:%s accuracy = %s' % (clf[0], metrics.accuracy_score(y_holdout, y_pred))\n",
    "                # filling predicted X_holdout into meta training set\n",
    "                meta_train[test_index, i] = y_pred\n",
    "                meta_test_i[:, j] = clf[1].predict(X_te)[:]\n",
    "            \n",
    "            meta_test[:, i] = meta_test_i.mean(1)\n",
    "        \n",
    "        self.meta_learner.fit(meta_train, y_tr)\n",
    "        y_result_pred = self.meta_learner.predict(meta_test)\n",
    "        print metrics.classification_report(y_te, y_result_pred)\n",
    "        print 'Final accuracy = %s' % (metrics.accuracy_score(y_te, y_result_pred))\n",
    "        return y_result_pred\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#baseLearner Default\n",
    "\n",
    "lg = LogisticRegression(random_state= 42)\n",
    "svm = SVC(random_state= 42)\n",
    "rf = RandomForestClassifier( random_state= 42, n_jobs=-1)\n",
    "knn = KNeighborsClassifier()\n",
    "base_learner = [['SVM', svm], ['Random Forest', rf], ['KNN',knn]]\n",
    "\n",
    "lg2 = LogisticRegression(penalty = 'l1', C = 10 ,random_state= 42)\n",
    "svm2 = SVC(kernel= 'rbf', C= 100.0, gamma= 0.01,random_state= 42)\n",
    "rf2 = RandomForestClassifier( criterion = 'gini',random_state= 42, n_jobs=-1)\n",
    "knn2 = KNeighborsClassifier(n_neighbors = 1)\n",
    "base_learner2 = [['SVM', svm2], ['Random Forest', rf2], ['KNN',knn2]]\n",
    "\n",
    "\n",
    "base_learner3 = [['SVM', svm], ['Logistic regression', lg], ['KNN',knn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.885714285714\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:Random Forest accuracy = 0.971428571429\n",
      "Base Learner:Random Forest accuracy = 0.885714285714\n",
      "Base Learner:Random Forest accuracy = 0.971428571429\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackingD = Stacking(42, 3, base_learner, lg)\n",
    "\n",
    "stackingD.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:SVM accuracy = 1.0\n",
      "Base Learner:SVM accuracy = 0.885714285714\n",
      "Base Learner:SVM accuracy = 1.0\n",
      "Base Learner:Random Forest accuracy = 0.971428571429\n",
      "Base Learner:Random Forest accuracy = 0.885714285714\n",
      "Base Learner:Random Forest accuracy = 0.971428571429\n",
      "Base Learner:KNN accuracy = 0.942857142857\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking2 = Stacking(42, 3, base_learner2, lg2)\n",
    "\n",
    "stacking2.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.885714285714\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:Logistic regression accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.914285714286\n",
      "Base Learner:Logistic regression accuracy = 0.971428571429\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.93      1.00      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "Final accuracy = 0.977777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 1, 0, 0])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    ''' X_tr = np.array(X_tr)\n",
    "        y_tr = np.array(y_tr)\n",
    "        X_te = np.array(X_te)\n",
    "        y_te = np.array(y_te)'''\n",
    "stacking3 = Stacking(42, 3, base_learner3, rf)\n",
    "\n",
    "stacking3.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
