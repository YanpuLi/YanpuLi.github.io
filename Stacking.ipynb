{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score , StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import KFold\n",
    "import xgboost as XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "logreg_tuned_parameters = [{'C': np.logspace(-1, 2, 4),'penalty':['l1','l2']}]\n",
    "classifiers.append([\"Logistic Regression\", LogisticRegression(random_state = 0), logreg_tuned_parameters])\n",
    "\n",
    "svm_tuned_parameters = [{'kernel': ['linear','rbf'],\n",
    "                             'C': np.logspace(-1, 2, 4),\n",
    "                             'gamma': np.logspace(-4, 0, 5)\n",
    "                        }]\n",
    "classifiers.append([\"SVM\", SVC(random_state = 0), svm_tuned_parameters])\n",
    " \n",
    "rf_tuned_parameters = [{\"criterion\": [\"gini\"]}]                \n",
    "classifiers.append([\"RandomForest\", RandomForestClassifier(random_state = 0, n_jobs=-1), rf_tuned_parameters])\n",
    "\n",
    "knn_tuned_parameters = [{\"n_neighbors\": [1, 3, 5, 10, 20]}]\n",
    "classifiers.append([\"kNN\", KNeighborsClassifier(),knn_tuned_parameters])\n",
    "\n",
    "classifiers.append([\"gnb\", GaussianNB(),{}])\n",
    "\n",
    "classifiers.append(['xgb', XGB.XGBClassifier(objective='binary:logistic',), {}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gsCV_accuracy(name,classifier, params, train, target):\n",
    " \n",
    "    print (name+\":\")\n",
    "    gs= GridSearchCV(classifier, params, n_jobs=-1, cv=5,scoring=\"accuracy\")\n",
    "    gs.fit(train, target)\n",
    "    #print (gs.best_params_, gs.best_score_)\n",
    "    \n",
    "    predict = gs.best_estimator_.predict(train)\n",
    "    print(metrics.classification_report(target,predict))\n",
    "    print(metrics.confusion_matrix(target, predict))\n",
    "    print(cross_val_score(gs.best_estimator_, train,target,cv= 5).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       0.97      0.95      0.96        37\n",
      "          2       0.95      0.97      0.96        37\n",
      "\n",
      "avg / total       0.97      0.97      0.97       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 35  2]\n",
      " [ 0  1 36]]\n",
      "0.953122529644\n",
      "SVM:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      0.95      0.97        37\n",
      "          2       0.95      1.00      0.97        37\n",
      "\n",
      "avg / total       0.98      0.98      0.98       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 35  2]\n",
      " [ 0  0 37]]\n",
      "0.970909090909\n",
      "RandomForest:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       0.97      1.00      0.99        37\n",
      "          2       1.00      0.97      0.99        37\n",
      "\n",
      "avg / total       0.99      0.99      0.99       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  1 36]]\n",
      "0.922727272727\n",
      "kNN:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      1.00      1.00        37\n",
      "          2       1.00      1.00      1.00        37\n",
      "\n",
      "avg / total       1.00      1.00      1.00       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  0 37]]\n",
      "0.952213438735\n",
      "gnb:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       0.92      0.92      0.92        37\n",
      "          2       0.92      0.92      0.92        37\n",
      "\n",
      "avg / total       0.94      0.94      0.94       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 34  3]\n",
      " [ 0  3 34]]\n",
      "0.923122529644\n",
      "xgb:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      1.00      1.00        37\n",
      "          2       1.00      1.00      1.00        37\n",
      "\n",
      "avg / total       1.00      1.00      1.00       105\n",
      "\n",
      "[[31  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  0 37]]\n",
      "0.943122529644\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classifiers)):\n",
    "    gsCV_accuracy(classifiers[i][0],classifiers[i][1], classifiers[i][2], X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stacking(object):\n",
    "\n",
    "    def __init__(self, seed, n_fold, base_learners, meta_learner):\n",
    "        self.seed = seed\n",
    "        self.n_fold = n_fold\n",
    "        self.base_learners = base_learners\n",
    "        self.meta_learner = meta_learner\n",
    "        self.T = len(base_learners) # num of base learners\n",
    "\n",
    "    def generateBaseLearner(self, X_tr, y_tr, X_te, y_te):\n",
    "    \n",
    "        n1 = X_tr.shape[0]\n",
    "        n2 = X_te.shape[0]\n",
    "\n",
    "        kf = KFold(n1, n_folds= self.n_fold, random_state= self.seed)\n",
    "\n",
    "        #constructing data for meta learner\n",
    "        meta_train = np.zeros((n1, self.T))\n",
    "        meta_test = np.zeros((n2, self.T))\n",
    "\n",
    "        for i, clf in enumerate(self.base_learners):\n",
    "            meta_test_i = np.zeros((n2, self.n_fold))\n",
    "            for j, (train_index, test_index) in enumerate(kf):\n",
    "                X_train = X_tr[train_index]\n",
    "                y_train = y_tr[train_index]\n",
    "                X_holdout = X_tr[test_index]\n",
    "                y_holdout = y_tr[test_index]\n",
    "           \n",
    "                clf[1].fit(X_train, y_train)\n",
    "                y_pred = clf[1].predict(X_holdout)[:]\n",
    "                \n",
    "                print 'Base Learner:%s accuracy = %s' % (clf[0], metrics.accuracy_score(y_holdout, y_pred))\n",
    "                # filling predicted X_holdout into meta training set\n",
    "                meta_train[test_index, i] = y_pred\n",
    "                meta_test_i[:, j] = clf[1].predict(X_te)[:]\n",
    "            \n",
    "            meta_test[:, i] = meta_test_i.mean(1)\n",
    "        \n",
    "        self.meta_learner.fit(meta_train, y_tr)\n",
    "        y_result_pred = self.meta_learner.predict(meta_test)\n",
    "        print metrics.classification_report(y_te, y_result_pred)\n",
    "        print(metrics.confusion_matrix(y_te, y_result_pred))\n",
    "        print 'Final accuracy = %s' % (metrics.accuracy_score(y_te, y_result_pred))\n",
    "        return y_result_pred\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#baseLearner Default\n",
    "\n",
    "lg = LogisticRegression(random_state= 0)\n",
    "svm = SVC(random_state= 0)\n",
    "rf = RandomForestClassifier( random_state= 0, n_jobs=-1)\n",
    "knn = KNeighborsClassifier()\n",
    "gnb = GaussianNB()\n",
    "xgb = XGB.XGBClassifier()\n",
    "\n",
    "\n",
    "lg2 = LogisticRegression(penalty = 'l1', C = 10 ,random_state= 0)\n",
    "svm2 = SVC(kernel= 'rbf', C= 100.0, gamma= 0.01,random_state= 0)\n",
    "rf2 = RandomForestClassifier( criterion = 'gini',random_state= 0, n_jobs=-1)\n",
    "knn2 = KNeighborsClassifier(n_neighbors = 1)\n",
    "base_learner2 = [['SVM', svm2], ['Random Forest', rf2], ['KNN',knn2]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.885714285714\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:Random Forest accuracy = 0.885714285714\n",
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learner = [['SVM', svm], ['Random Forest', rf], ['KNN',knn]]\n",
    "stackingD = Stacking(0, 3, base_learner, lg)\n",
    "stackingD.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:SVM accuracy = 1.0\n",
      "Base Learner:SVM accuracy = 1.0\n",
      "Base Learner:SVM accuracy = 0.857142857143\n",
      "Base Learner:SVM accuracy = 1.0\n",
      "Base Learner:SVM accuracy = 1.0\n",
      "Base Learner:Random Forest accuracy = 0.952380952381\n",
      "Base Learner:Random Forest accuracy = 0.952380952381\n",
      "Base Learner:Random Forest accuracy = 0.857142857143\n",
      "Base Learner:Random Forest accuracy = 1.0\n",
      "Base Learner:Random Forest accuracy = 0.952380952381\n",
      "Base Learner:KNN accuracy = 0.952380952381\n",
      "Base Learner:KNN accuracy = 0.952380952381\n",
      "Base Learner:KNN accuracy = 0.857142857143\n",
      "Base Learner:KNN accuracy = 1.0\n",
      "Base Learner:KNN accuracy = 0.952380952381\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking2 = Stacking(0, 5, base_learner2, lg2)\n",
    "\n",
    "stacking2.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.885714285714\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:Logistic regression accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.914285714286\n",
      "Base Learner:Logistic regression accuracy = 0.971428571429\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    ''' X_tr = np.array(X_tr)\n",
    "        y_tr = np.array(y_tr)\n",
    "        X_te = np.array(X_te)\n",
    "        y_te = np.array(y_te)'''\n",
    "base_learner3 = [['SVM', svm], ['Logistic regression', lg], ['KNN',knn]]\n",
    "stacking3 = Stacking(0, 3, base_learner3, rf)\n",
    "\n",
    "stacking3.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:Random Forest accuracy = 0.885714285714\n",
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.914285714286\n",
      "Base Learner:Logistic regression accuracy = 0.971428571429\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.914285714286\n",
      "Base Learner:KNN accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.93      1.00      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "Final accuracy = 0.977777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 1, 0, 0])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learner4 = [['Random Forest', rf], ['Logistic regression', lg], ['KNN',knn]]\n",
    "stacking4 = Stacking(0, 3, base_learner4, svm)\n",
    "\n",
    "stacking4.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:Random Forest accuracy = 0.885714285714\n",
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.914285714286\n",
      "Base Learner:Logistic regression accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.885714285714\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learner5 = [['Random Forest', rf], ['Logistic regression', lg], ['SVM', svm]]\n",
    "stacking5 = Stacking(0, 3, base_learner5, knn)\n",
    "\n",
    "stacking5.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:Random Forest accuracy = 0.885714285714\n",
      "Base Learner:Random Forest accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.942857142857\n",
      "Base Learner:Logistic regression accuracy = 0.914285714286\n",
      "Base Learner:Logistic regression accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:SVM accuracy = 0.885714285714\n",
      "Base Learner:SVM accuracy = 0.971428571429\n",
      "Base Learner:knn accuracy = 0.914285714286\n",
      "Base Learner:knn accuracy = 0.914285714286\n",
      "Base Learner:knn accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learner6 = [['Random Forest', rf], ['Logistic regression', lg], ['SVM', svm], ['knn', knn]]\n",
    "stacking6 = Stacking(0, 3, base_learner6, gnb)\n",
    "\n",
    "stacking6.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-5b984acb48ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbase_learner3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'knn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstacking3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_learner3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state= 13)\n",
    "rf = RandomForestClassifier(random_state= 13)\n",
    "\n",
    "base_learner3 = [ ['lg', lg], ['knn', knn], ['svm', svm]]\n",
    "stacking3 = Stacking(0, 3, base_learner3, gnb)\n",
    "\n",
    "stacking3.generateBaseLearner(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learner:lg accuracy = 0.942857142857\n",
      "Base Learner:lg accuracy = 0.914285714286\n",
      "Base Learner:lg accuracy = 0.971428571429\n",
      "Base Learner:knn accuracy = 0.914285714286\n",
      "Base Learner:knn accuracy = 0.914285714286\n",
      "Base Learner:knn accuracy = 0.971428571429\n",
      "Base Learner:svm accuracy = 0.971428571429\n",
      "Base Learner:svm accuracy = 0.885714285714\n",
      "Base Learner:svm accuracy = 0.971428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Final accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state= 0)\n",
    "rf = RandomForestClassifier(random_state= 0)\n",
    "base_learner3 = [ ['lg', lg], ['knn', knn], ['svm', svm]]\n",
    "stacking3 = Stacking(0, 3, base_learner3, gnb)\n",
    "\n",
    "stacking3.generateBaseLearner(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
