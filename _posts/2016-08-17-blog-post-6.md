---
title: 'Very Confusing Pairs to MeðŸ¤”ðŸ˜¥ðŸ˜´'
date: 2016-08-17
permalink: /posts/2016/08/blog-post-6
---
This post is used for elaborating details and make comparisons of some very similar and confusing pairs to me.


Bias & Variance
======
Bias is an error from erroneous assumptions in the learning algorithm. Variance is an error from sensitivity to small fluctuations in the training set. This is the definition from Wiki. But it is still kind of confusing. To me, bias measures how far your prediction is away from the true value. Variance measures how far your prediction is away from the mean value, meaning how scattered your prediction is. Here is a very famous visualization of these two items. You can easily get my points from it.
![bias&var](/images/biasvar1.png)
Figure 1. Bias and Variance Visualization

Then, let's take a look at the mathematical definitions. Assuming a relationship between a covariate X and Y, let Y = f(X) + Ïµ, where Ïµ follows a normal distribution, Ïµâˆ¼N(0,Ïƒ<sub>Ïµ</sub>), fÌ‚(X) denotes the estimated model.
In this case, the mean squared error of a point x is:
<p float="left"><img src="/images/equation.jpg" width="500" /></p>
So the equation is composed of 3 parts: variance, bias and irreducible error which is the noise term in the true relationship and can't be reduced by any model.

Tradeoff between variance and bias: With the increase in model complexity, the bias drops down and var goes up. At the same time, it will lead to overfitting, meaning your model performs too well on the training set, but poorly on testing data. Keep your model simple or introducing regularization are the methods to control bias. For variance, you can construct your data with resampling methods, then multiple models would be generated on these datasets, and finally got averaged to reduce variance.
<p float="left"><img src="/images/biasvar2.png" width="400" /></p>
Figure 2. Bias & Var Tradeoff

Cost Function & Loss Function
======
Both functions deal with training error. In Andrew Ng's Neural Networks and Deep Learning course, he gives very specific definition of the two: the loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set. Then, to optimize the loss function or cost function), we can get the <ins>objective function</ins>, which is composed of <ins>empirical risk</ins> (related with loss/ cost function) and <ins>structural risk</ins> (related with regularization).


L1 & L2
======
L1-norm loss function tries to minimize the sum of absolute error between the targets and predictions. while L2-norm loss function changes absolute value into squared one. If the error > 1, then L2 will make the error become larger than L1. In this way, L2 is more sensitive than L1 on outliers.

Regularization is used to prevent overfitting by introducing a regularization term in the objective function to add penalty. L1 (lasso) is the sum of weights and l2 is the sum of square of weights. L1 can change large coefficients into 0, while L2 can only make the coefficient close to 0. Hence, L1 can works as a feature selection process. 
<p float="left"><img src="/images/l1l2.png" width="350" /></p>
Figure 3. L1 & L2

Classification Evaluation
======
<p float="left"><img src="/images/classe.png" width="380" /></p>
Figure 4. Diagnostic Testing Matrix

**Specificity & Sensitivity:** Sensitivity (recall,TPR) meansures the proportion of positives that are correctly identified. Specificity measures how good a test is at avoiding false alarms.

**Precision & Recall:** Precision tells the fraction of retrieved instances that are relevant (Precision = TP / predicted positives). Recall calculates the fraction of relevant instances which have been retrieved (Recall = TP / actual positives). 
<p float="left"><img src="/images/recall.png" width="240" /></p>
Figure 5. Precision & Recall Curve

So when make predictions of earthquake, we don't mind to make too many alarms. Because our goal is to minimize the casualties, we want to have higher recall at the expense of precision. It will become a different when finding criminals. We will try to keep a high precision value. This is very understandable, as we don't want to make troubles to the innocent ones. Of course, we want both precision and recall to be of high score, but there is a tradeoff between the two. So the decision should be made under the specific situation, whether we want high precision or more retrieve more information. In the precision/ recall curve, if the curve is more close to the point (1,1), the performance is better. Precision (P) and recall (R) can be combined in one meansure (F). If Î² -> 0, then we give more importance to P, else we focus more on R. 

F<sub>Î²</sub>=(Î²<sup>2</sup>+1)PR/ Î²<sup>2</sup>P+ R 

When Î²=1, we get F1, which is a single measure of performance of the test. F1=2(PR/ (P+R))

**Micro-averaging  & Macro-averaging:** 

For multi-class problems, let C<sub>1</sub>,..., C<sub>k</sub> denote k classes. For each class C<sub>i</sub>, P<sub>i</sub> = TP<sub>i</sub> / (TP<sub>i</sub> + FP<sub>i</sub>); R<sub>i</sub> = TP<sub>i</sub> / (TP<sub>i</sub> + FN<sub>i</sub>)

Micro-averaging: P<sup>Î¼</sup>=TP/ (TP+FP), R<sup>Î¼</sup>=TP/ (TP+FN); 

Macro-averaging:  P<sup>M</sup>=1/K * (âˆ‘<sub>i</sub>P<sub>i</sub>); R<sup>M</sup>=1/K * (âˆ‘<sub>i</sub>R<sub>i</sub>)

**ROC:** It intends to evaluate the performance of binary classifier, with tpr as y axis and fpr as x axis. tpr=TP/ (TP+FN), fraction of positive examples correctly classified; fpr=FP/ (FP+TN), fraction of negative examples incorrectlt classified. Take a binary classifier (0,1) as example, point (0,0) in the Fig. 6 will always predict 0, (1,1) will always give the output 1.
<p float="left"><img src="/images/ROC.png" width="240" /></p>
Figure 6. ROC Curve

**Skewed Dataset:** If your dataset is highly skewed, it's better to user precision recall curve than ROC to evaluate your classifier.
![example](/images/eg.jpg)

**To be continued...**

Reference
------
[1]. http://scott.fortmann-roe.com/docs/BiasVariance.html

[2]. https://stats.stackexchange.com/questions/179026/objective-function-cost-function-loss-function-are-they-the-same-thing

[3]. http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/

[4]. https://en.wikipedia.org/wiki/Sensitivity_and_specificity

[5]. http://mlwiki.org/index.php/Precision_and_Recall


