---
title: 'Very Confusing Pairs to Meヰ'
date: 2016-08-17
permalink: /posts/2016/08/blog-post-6
---
This post is used for elaborating details and make comparisons of some very similar and confusing pairs to me.


Bias & Variance
======
Bias is an error from erroneous assumptions in the learning algorithm. Variance is an error from sensitivity to small fluctuations in the training set. This is the definition from Wiki. But it is still kind of confusing. To me, bias measures how far your prediction is away from the true value. Variance measures how far your prediction is away from the mean value, meaning how scattered your prediction is. Here is a very famous visualization of these two items. You can easily get my points from it.
![bias&var](/images/biasvar1.png)
Figure 1. Bias and Variance Visualization

Then, let's take a look at the mathematical definitions. Assuming a relationship between a covariate X and Y, let Y = f(X) + 系, where 系 follows a normal distribution, 系N(0,<sub>系</sub>), f(X) denotes the estimated model.
In this case, the mean squared error of a point x is:
<p float="left"><img src="/images/equation.jpg" width="500" /></p>
So the equation is composed of 3 parts: variance, bias and irreducible error which is the noise term in the true relationship and can't be reduced by any model.

Tradeoff between variance and bias: With the increase in model complexity, the bias drops down and var goes up. At the same time, it will lead to overfitting, meaning your model performs too well on the training set, but poorly on testing data. Keep your model simple or introducing regularization are the methods to control bias. For variance, you can construct your data with resampling methods, then multiple models would be generated on these datasets, and finally got averaged to reduce variance.
<p float="left"><img src="/images/biasvar2.png" width="400" /></p>
Figure 2. Bias & Var Tradeoff

Cost Function & Loss Function
======
Both functions deal with training error. In Andrew Ng's Neural Networks and Deep Learning course, he gives very specific definition of the two: the loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set. Then, to optimize the loss function or cost function), we can get the objective function, which is composed of empirical risk (related with loss/ cost function) and structural risk (related with regularization).


L1 & L2
======


Classification Evaluation
======

###Specificity & Sensitivity

###Precision & Recall

**To be continued...**

Reference
------
[1]. http://scott.fortmann-roe.com/docs/BiasVariance.html

[2]. https://stats.stackexchange.com/questions/179026/objective-function-cost-function-loss-function-are-they-the-same-thing

[3].

[4]. https://en.wikipedia.org/wiki/Sensitivity_and_specificity


