---
title: 'Tree Series 1: Decision Tree, Random Forest & GBDT'
date: 2018-05-16
permalink: /posts/2018/05/blog-post-12/
comments: true
tags:
  - Tree
 
---

Tree is one of the most widely used model, with a large family(regression tree, classification tree, bagging: RF, boosting: GBDT), and implementations(ID3, C4.5, CART). This series of posts will start from a brief introduction of the basic principles of DT, RF and GBDT, then dive deeper into this family by making comparisons.

## Decision Tree

There are two main stages for generating a decision tree: constructing a full tree by greedily find the best split, pruning the tree to avoid overfitting. 
<p float="left">
  <img src="/images/DT1.png" width="600" />
</p>

**Figure 1. Decision Tree Building Strategy Summarization**



Reference
========

[1]. BISHOP, C. M. (2016). PATTERN RECOGNITION AND MACHINE LEARNING. S.l.: SPRINGER-VERLAG NEW YORK.

[2]. Murphy, K. P. (2013). Machine learning: a probabilistic perspective. Cambridge, Mass.: MIT Press.

[3]. James, G. (2013). An Introduction to Statistical Learning. Springer.

[4]. https://people.csail.mit.edu/dsontag/courses/ml16/slides/lecture11.pdf



------