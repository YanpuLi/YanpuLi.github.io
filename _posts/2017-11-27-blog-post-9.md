---
title: 'Introduction of Reinforcement Learning'
date: 2017-11-27
permalink: /posts/2017/11/blog-post-9/
tags:
  - reinforcement learning
---

## Introduction
Recently, I have read some papers about Reinforcement Learning (RL). To me, it's quite an interesting topic. So I wrote this post to make summaries. RL is about through interacting with the environment sequentially, the agent will gradually learn how to take actions to maximize an accumulative reward. It acts just like a human being, good behavior results in reward, bad one leads to punishment. This concept is easy to understand. But before illustrating the core elements of RL, I'd like to stop here and ask a few questions. We've already got a lot of super powerful "learning", like machine learning, sub-areas: supervised learning, unsupervised learning. What's the relationship between RL and these existing ones? Why RL is still necessary? RL is also a sub-area in machine learning. You can see the difference in the table below.
 
|      | Supervised Learning | Unsupervised Learning    |         RL                     |
|----- |-------------------       | --------------------------| --------------------------------------- |
|Input | labeled data             | unlabeled data            | initial state           |
|Working Process| train on training set, look for model to optimize certain object function   | look for model to gain insights into data                 | learn from environment in **a sequential process**, take actions, either being punished or rewarded, aiming to maximize reward,             |
|Validation    | validate on testing set |             | evaluate by reward function                    |
|Application  | regression, classification| clustering, segmentation, association| prediction, control|

## Core Elements
A RL system contains 6 core elements: agent, environment, policy, reward signal, value function and model of the environment. In my opinion, the agent and environment is kind like entity, and the rest four elements are like attributes belong to entity. On agent side: **Policy** helps agent map environment states to corresponding actions, which can be viewed as a set of responding behaviors in psychology. It can either be deterministic, so a = π(s); or stochastic, π(a|s) = P[A=a| S=s]. **Reward signal** defines good/ bad events for agent. Thus, if the corresponding reward for an action is low, then the policy may be changed in the next step. **Value function** predicts future rewards. 

On environment side: **Model** is optional in RL system, it could predict what environment will do next, including next reward and next state. So the basic process is from one state to another, the agent choose action based on information (current state) of environment. This action will be emitted and try to change the state of environment. And the environment will in turn outputs a reward to the agent. No one tells the agent what to do, it needs to learn through a a trial-error-correct process.

<p float="left">
  <img src="/images/rl1.png" width="280" />
</p>
Figure 1. Agent & Environment Interactions

## Markov Decision Process
This process can be defined as a Markov Decision Process (MDP), if and only if its future state are independent of any previous states or actions. Represented as a 5-tuple (S, A, P, R, γ). S: set of state, A: set of action. P: set of policy, R: reward function, γ: a discount factor, ranging from 0 to 1. When the agent observe the environment indirectly, it becomes a partiarlly observable Markov Decision Process (POMDP).

Reference
========
[1]. Sutton, R. S. & Barto, A. G. (1998) Reinforcement Learning: An Introduction. Cambridge, Mass.: MIT Press.

[2]. Leslie, P. K. (1996) Reinforcement learning: A survey. Journal of artificial intelligence research 4, 237-285

[3]. https://en.wikipedia.org/wiki/Bellman_equation

[4]. http://www.cs.ubc.ca/~murphyk/Bayes/pomdp.html

[5]. Si, J. (2004) Reinforcement Learning and Its Relationship to Supervised Learning. doi: 10.1002/9780470544785.ch2

[6]. Kai, A. (2017) A Brief Survey of Deep Reinforcement Learning. IEEE Signal Processing Magazine, 34(6), 26-38, arXiv:1406.2040

[7]. Yuxi Li. (2017) Deep Reinforcement Learning: An Overview. arXiv preprint arXiv:1701.07274
https://zhuanlan.zhihu.com/p/32318301
https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/
http://www.cs.ubc.ca/~murphyk/Bayes/pomdp.html

------