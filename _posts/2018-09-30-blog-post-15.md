---
title: 'Risk Prediction Concept for Medical/Healthcare Data'
date: 2018-09-30
permalink: /posts/2018/09/blog-post-15/
comments: true
tags:
  - Risk Prediction
  - Healthcare
 
---

This post is for explaining some basic statistical concepts used in disease morbidity risk prediction. As being a CS student, I have found a hard time figuring out these statistical concepts, hope my summary would be helpful for you.

### Relative Risk vs Odds Ratio
Before explaining the concepts of these two terms, it is more fundamental to get clear with the following table, which is for calculating the above terms. 'Disease' contains two groups ( e.g. a person with certain disease, like CHD, or without CHD). 'Exposure': whether that person is exposed to certain risk factor (e.g. somking or no smoking; gender as male or female).  `Attention: 'Disease' can be regarded as 'Actual Class' in confusion matrix, but 'Exposure' is not equivalent to the 'Predicted Class'.`
<p float="left">
  <img src="/images/relative risk1.png" width="400" />
</p>
### Figure 1. Disease & Exposure Table

**Relative Risk, RR**: also called as risk ratio, rate ratio, 'is the ratio of the probability of an outcome in an exposed group to the probability of an outcome in an unexposed group'(referenced from Wiki). In my understanding, it means the ratio of probability that a CHD patient has smoking experience vs without smoking experience. In this sense, it becomes easy to interpret RR. 

+ RR = 1: the risk factor(smoking) has nothing to do with the probability that the person would suffer from CHD. After all, Pr(CHD\|smoking) == Pr(CHD\|non-smoking). 
+ RR > 1: meaning smoking is positively related with CHD, it's a risk factor, the larger the value is, the more important the factor will be.
+ RR < 1: the relationship between the two are negative, it can be viewed as a protect factor.

<img src="https://latex.codecogs.com/svg.latex? RR = {Pr(CHD\|smoking)}/{Pr(CHD\|non-smoking)} = \pi_11" title="p" />

**Odds**:

<img src="https://latex.codecogs.com/svg.latex? g_i(w) <= 0, i = 1,...,k" title="p" />
**Odds Ratio, OR**:


### Similarity Control & Knowledge Transfer
**Similarity Control** 

This topic has been mainly discussed in [1] by taking SVM as the example. Vladimir describes the topic as "The mechanism to control students' concept of similarity between training examples". The general idea is: in a seperable sample set, svm only needs to estimate n parameters of w, while in a non-seperable one, it becomes n+l (n parameters of w defines the hyperplane and l values of slacks, which belongs to high VC dimension).

In SVM+, it maps vectors x into space Z and x<sup> * </sup> into Z<sup> * </sup>, which represents the decision space and correcting (slack) space. Vladimir has changed the traditional Lagrangian function (SVM) into:
<p float="left">
  <img src="/images/pi2.png" width="540" />
</p>
subject to constraints:
<p float="left">
  <img src="/images/pi3.png" width="220" />
</p>
The first two items represent the separable part, the rest stands for the correcting space. Note that if α<sub>i</sub> +β<sub>i</sub> −C =0 or  γ tends to 0, then the solution will be back to traditional SVM. This happens when similarity measures in Z<sup>* </sup> are not appropriate.
### Knowledge Transfer
The basic idea is teacher masters rules of mapping X<sup>* </sup> to y, which is much smaller than the rules in original space X. Students need to know how to transfer useful features in X<sup>* </sup> into X. Also, as it only requires a small fraction of the entire knowledge, it doesn't need to work on large-sized sample set.

Reference
========

[1]. Vladimir, V., Akshay, V. A new learning paradigm: Learning using privileged information. Neural Networks 22(2009), 544-557. doi:10.1016/j.neunet.2009.06.042

[2]. Vladimir, V., Rauf, I. Learning Using Privileged Information: Similarity Control and Knowledge Transfer. Journal of Machine Learning Research 16(2015), 2023-2049.




------