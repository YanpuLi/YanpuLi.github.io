---
title: 'Logistic Regression'
date: 2015-11-15
permalink: /posts/2015/11/blog-post-1/
---
Introduction
======
Logistic regression is to directly estimate the distribution of a conditional probability model from the training set, and obtain the unknown parameters by using maximum likelihood estimation. 

The model can be defined as:
p(Y=1|X) = g(θ<sup>T</sup>X) = 1/(1+ e<sup>-θ<sup>T</sup>X</sup>)

where g(z) = 1/(1+ e<sup>-z</sup>) is the logistic function (sigmoid function), θ = <θ<sub>0</sub>, θ<sub>1</sub>,..., θ<sub>d</sub>>, X = <1, X<sub>1</sub>,..., X<sub>d</sub>>

As g(z) goes towards 1, when z → ∞; towards 0, when z → -∞, shown in Fig. 1
<p float="left"><img src="/images/lg1.png" width="220" /></p>
###Figure 1. Sigmoid Function

So our model can be represented as, 
<p float="left"><img src="/images/lg2.png" width="220" /></p>
<p float="left"><img src="/images/lg2.png" width="220" /></p>

Aren't headings cool?
------