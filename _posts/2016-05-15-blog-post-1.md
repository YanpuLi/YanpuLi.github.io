---
title: 'Logistic Regression'
date: 2016-05-15
permalink: /posts/2016/05/blog-post-1/
---
Introduction
======
Logistic regression is to directly estimate the distribution of a conditional probability model from the training set, and obtain the unknown parameters by using maximum likelihood estimation. 

The model can be defined as:
p(Y=1|X) = g(θ<sup>T</sup>X) = 1/(1+ e<sup>-θ<sup>T</sup>X</sup>)

where g(z) = 1/(1+ e<sup>-z</sup>) is the logistic function (sigmoid function), θ = <θ<sub>0</sub>, θ<sub>1</sub>,..., θ<sub>d</sub>>, X = <1, X<sub>1</sub>,..., X<sub>d</sub>>

As g(z) goes towards 1, when z → ∞; towards 0, when z → -∞, shown in Fig. 1
<p float="left"><img src="/images/lg1.png" width="220" /></p>
Figure 1. Sigmoid Function

So our model can be represented as, 
<p float="left"><img src="/images/lg2.png" width="220" /></p>
<p float="left"><img src="/images/lg3.png" width="230" /></p>
<p float="left"><img src="/images/lg4.png" width="380" /></p>
##MLE

Assuming all the training set were generated independently, so the likelihood of the parameters can be represented as:
<p float="left"><img src="/images/lg5.png" width="380" /></p>
Then, we want to obtain θ which maximize the log likelihood: 
<p float="left"><img src="/images/lg6.png" width="380" /></p>
##Gradient Ascent

As the conditional likelihood for logistic regression is concave, we can find optimal θ by using gradient ascent. Repeatedly update the weights in the direction of the gradient:
<p float="left"><img src="/images/lg7.png" width="260" /></p>
<p float="left"><img src="/images/lg8.png" width="260" /></p>
where α is a positive constant learning rate to control the size of each step. As l(θ) is a concave function, the gradient ascent procedure will converge to a global maximum rather than a local minimum.
##Regularization

Regularization is used for reduce overfitting by adding penalty for large values of θ. One way is to add L<sub>2</sub> (ridge) norm to the log likelihood:
<p float="left"><img src="/images/lg9.png" width="280" /></p>
The other is using L<sub>1</sub> (lasso) norm:
<p float="left"><img src="/images/lg10.png" width="280" /></p>

Experiment: Malicious URL Dection
======
The dataset contains around 420,000 pieces url records. 
Table 1

| url           | label   |    
| ---------        | ------ | 
| iamagameaddict.com     | bad  | 
| slightlyoffcenter.net    | bad   | 

About the format of a url: it contains protocol, host name (primary domain) and so on. So in the 1st step, we need to cut a whole url into Tokens 























Aren't headings cool?
------