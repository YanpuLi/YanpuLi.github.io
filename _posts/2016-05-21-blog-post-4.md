---
title: 'SVM: Support Vector Machine'
date: 2016-05-21
permalink: /posts/2016/05/blog-post-4/
tags:
  - ML
---

The key of SVM is to find a hyperplane, which is built on some important instances (support vectors), to seperate data instances correctly. Here comes with a very contradictory process to construct the plane: the margin of the hyperplane is chosen to be <ins>the smallest distance </ins>between decision boundary and support vectors; at the same time the decision boundary need to be the one which the margin is <ins>maximized</ins>. This is because there can be many hyperplanes (Fig. 1) to seperate data correctly. Choosing the one which leads to the largest gap between both classes may be more resistant to any perturbation of the training data. 

<p float="left">
  <img src="/images/svm_multiple_hyperplanes.png" width="250" />
  <img src="/images/svm_maximum_margin.png" width="250" /> 
</p>
### Figure 1. infinite hyperplanes and maximum margin

Functional Margin & geometric margin
======

Let's take a two-class classification problem using linear models as the example.  

y(x) = **w**<sup>T</sup>φ(x) + b                                                                                                

**W**: a weight vector; φ(x): input vector; b: bias; training set: N input vectors x<sub>1</sub>,..., x<sub>N</sub>, with corresponding target values t<sub>1</sub>,..., t<sub>N</sub> where t<sub>n</sub> ∈{−1,1}; so the decision boundary can be represented as **w**<sup>T</sup>φ(x) + b = 0; for the 2 classes, one satisfies y(x<sub>n</sub>) > 0, meaning t<sub>n</sub> = 1; the other satisfies y(x<sub>n</sub>) < 0, meaning t<sub>n</sub> = -1, so that t<sub>n</sub>\*y(x<sub>n</sub>) > 0. In this way, we define the functional margin as γ = t\*(**w**<sup>T</sup>φ(x) + b), and we want to find the minimum functional margin over the whole training set. 

<img src="https://latex.codecogs.com/svg.latex? \hat{\gamma} = min \hat{\gamma_i} (i = 1,..., N)" title="p" />
But when we multiply w, b, the value of functional margin will change too. So we introduce geometric margin, which represents the distance between a point to the hyperplane. <img src="https://latex.codecogs.com/svg.latex? {\gamma} = \frac{1}{||w||}* \hat{\gamma}" title="p" />

For the training set, <img src="https://latex.codecogs.com/svg.latex? {\gamma} = min {\gamma_i}" title="p" />

Maximum Margin Classifier
======           

So the problem becomes:     
<p float="left"><img src="/images/svm_formula3.png" width="300" /></p>                     

As we have mentioned before, if we change w → κw and b → κb, the distance from x<sub>n</sub> to the decision boundary is unchanged. So we set this freedom to 
t<sub>n</sub> (w<sup>T</sup>φ(x<sub>n</sub>) + b)= 1; so all training set will meet the constraint: t<sub>n</sub> (w<sup>T</sup>φ(x<sub>n</sub>)+b) >= 1, n=1,...,N.

Then the problem can be changed into: 
<p float="left"><img src="/images/svm_formula4.png" width="160" /> </p>    
s.t. t<sub>n</sub> (w<sup>T</sup>φ(x<sub>n</sub>)+b) >= 1, n=1,...,N.

To make this constrained optimization problem much easier to solve, Lagrange Duality has been introduced. (a<sub>n</sub> represents the Lagrange multiplier, a<sub>n</sub> >= 0) This procedure can also help us to work on non-linear classification problem, by introducing a kernel function.
<p float="left"><img src="/images/svm_formula5.png" width="400" /></p>  

The problem becomes:

<p float="left"><img src="/images/add1.png" width="400" /></p>  

The dual problem is:

<p float="left"><img src="/images/add2.png" width="300" /></p>  

Details of this transformation is shown at the end of this blog.

Then, set the derivatives of L(w, b, a) with respect to w, b to 0, we get 2 conditions:
<p float="left"><img src="/images/svm_formula6.png" width="170" /></p>  
Put these 2 conditions back into previous formula: 
<p float="left"><img src="/images/svm_formula7.png" width="400" /></p>  
s.t.
<p float="left"><img src="/images/svm_formula8.png" width="250" /></p>  
**Soft Margin:**
Introducing slack variable ξ<sub>n</sub> to allow misclassified data:
ξ<sub>n</sub> = 0, represents data on the correct side of margin, or correctly classified;
0 < ξ<sub>n</sub> <= 1, means data inside of margin, but on correct side of decision boundary;
ξ<sub>n</sub> > 1, denotes data on the wrong side of decision boundary.
Thus, we want to minimize:
<p float="left"><img src="/images/svm_formula9.png" width="150" /></p> 
where C > 0, it controls the trade-off between the slack variable and the margin. Then, the Lagrangian formula is defined as:
<p float="left"><img src="/images/svm_formula10.png" width="450" /></p> 
With KKT conditions:
<p float="left"><img src="/images/svm_formula11.png" width="180" /></p> 
Again set the derivatives with respect to w, b, ξ<sub>n</sub> to 0, then we get, and obtain the new form of Lagrangian, in which we maximize it with respect to a:
<p float="left"><img src="/images/svm_formula12.png" width="220" /></p> 
<p float="left"><img src="/images/svm_formula13.png" width="380" /></p> 
s.t. 
<p float="left"><img src="/images/svm_formula14.png" width="100" /></p> 
Then, we can obtain b by averaging:
<p float="left"><img src="/images/svm_formula15.png" width="330" /></p> 

**Inner Product:** 
In previous formula, k(x<sub>n</sub>, x<sub>m</sub>) can be viewed as the inner product of two vectors. 
* If x<sub>n</sub>, x<sub>m</sub> are parallel, there inner product is maximized.
* If x<sub>n</sub>, x<sub>m</sub> are perpendicular, then their inner product is 0.

Let's take a look back at the Lagrangian formula. Being perpendicular means two features are completely different, as there product is 0, it won't influence the value of L. However, if they are parallel, meaning x<sub>n</sub>, x<sub>m</sub>, both features are completely alike. if 2 features predict the same class output, then a<sub>n</sub>a<sub>m</sub>t<sub>n</sub>t<sub>m</sub>k(x<sub>n</sub>, x<sub>m</sub>) will be positive, meaning L will decrease; if 2 features gives the opposite predictions, then a<sub>n</sub>a<sub>m</sub>t<sub>n</sub>t<sub>m</sub>k(x<sub>n</sub>, x<sub>m</sub>) is negative, so the value of L will increase. This is the situation we want most, as it can tell the 2 classes apart.

Lagrange Duality
======  

At the end of this post, I will give a brief summary about Lagrange Duality. 
Assume the original optimization problem as:

<img src="https://latex.codecogs.com/svg.latex? min_w f(w)" title="p" />

s.t. <img src="https://latex.codecogs.com/svg.latex? g_i(w) <= 0, i = 1,...,k" title="p" />
    
   <img src="https://latex.codecogs.com/svg.latex? h_i(w) = 0, i = 1,...,l" title="p" />

The corresponding Lagrange formula:
<p float="left"><img src="/images/add3.png" width="500" /></p> 

The problem becomes: 

<img src="https://latex.codecogs.com/svg.latex? \theta_p{(w)} = max_{\alpha, \beta: \alpha_i >0} {\mathcal  {L}(w, \alpha, \beta)}" title="p" /> with θ<sub>p</sub>(w) = f(w), if w satisfies the constraints, otherwise, θ<sub>p</sub>(w) = ∞. So our goal is to minimize θ<sub>p</sub>(w), which is <img src="https://latex.codecogs.com/svg.latex? min_w {\theta}_p{(w)} = {min_w} max_{\alpha, \beta: {\alpha}_i >0} {\mathcal  {L}(w, \alpha, \beta)}" title="p" />

Set the duality problem:

<img src="https://latex.codecogs.com/svg.latex? {\theta}_D{(\alpha, \beta)} = min_w {\mathcal  L(w, \alpha, \beta)}" title="p" />

<img src="https://latex.codecogs.com/svg.latex? max_{\alpha, \beta: \alpha_i >0} { \theta_D(\alpha, \beta)} = max_{\alpha, \beta: \alpha_i >0} min_w {\mathcal  L(w, \alpha, \beta)}" title="p" />

<img src="https://latex.codecogs.com/svg.latex? d^* = max_{\alpha, \beta: \alpha_i >0} min_w {\mathcal  L(w, \alpha, \beta)}" title="p" />

<img src="https://latex.codecogs.com/svg.latex? p^* = {min_w} max_{\alpha, \beta: \alpha_i >0} {\mathcal  L(w, \alpha, \beta)}" title="p" />

<img src="https://latex.codecogs.com/svg.latex? d^* <= p^* " title="p" />


References
------
[1]. BISHOP, C. M. (2016). PATTERN RECOGNITION AND MACHINE LEARNING. S.l.: SPRINGER-VERLAG NEW YORK.

[2]. Murphy, K. P. (2013). Machine learning: a probabilistic perspective. Cambridge, Mass.: MIT Press.

[3]. http://logos.name/archives/304

[4]. http://www.cnblogs.com/90zeng/p/Lagrange_duality.html

